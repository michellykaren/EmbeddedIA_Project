{"cells":[{"cell_type":"markdown","metadata":{"id":"mfwQTFZl9Gf7"},"source":["# **Preprocessing Dataset**"]},{"cell_type":"markdown","metadata":{"id":"TMcgVaRpXC0g"},"source":["**UNZIP DATASET**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"f2FZ7OoQAOcb"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32md:\\S9\\Embedded_IA\\data\\esca_dataset\\esca_dataset-CNN.ipynb Cellule 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/S9/Embedded_IA/data/esca_dataset/esca_dataset-CNN.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/S9/Embedded_IA/data/esca_dataset/esca_dataset-CNN.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Tv1MNz0EA8uT"},"outputs":[{"name":"stderr","output_type":"stream","text":["'unzip' n'est pas reconnu en tant que commande interne\n","ou externe, un programme ex�cutable ou un fichier de commandes.\n","'ls' n'est pas reconnu en tant que commande interne\n","ou externe, un programme ex�cutable ou un fichier de commandes.\n"]}],"source":["dataset_name = \"/augmented_esca_dataset\"\n","dataset_destination = \"/augmented_esca_dataset\"\n","\n","!unzip  $dataset_name\".zip\" -d $dataset_destination\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"ss4aXqoi9OaZ"},"source":["**LIBRARIES**"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MKV_DpMO9dI5"},"outputs":[],"source":["from PIL import Image\n","import numpy as np\n","from numpy import random\n","\n","\n","import os\n","import pathlib\n","import random"]},{"cell_type":"markdown","metadata":{"id":"r5L_AeAq9JhF"},"source":["**DIRECTORY**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnNOs8QB9eek"},"outputs":[],"source":["# directory of dataset\n","#dir_original = \"/content/drive/MyDrive/augmented_esca_dataset/content/esca_dataset/augmented_esca_dataset\"\n","dir_original = \"augmented_esca_dataset\"\n","\n","# name of new dataset\n","#dir_processed = \"/content/drive/MyDrive/augmented_esca_dataset_splited\"\n","dir_processed = \"augmented_esca_dataset_splited\"\n"]},{"cell_type":"markdown","metadata":{"id":"xL2JPD_S9QJr"},"source":["**PARAMETERS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cxtO-Z769gZe"},"outputs":[],"source":["# size of new images\n","size = 1280, 720"]},{"cell_type":"markdown","metadata":{"id":"uPd-i4dw9TbW"},"source":["**EXTRACTION OF DATASET INFORMATION**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWYUjeDB9iEz"},"outputs":[],"source":["data_dir = pathlib.Path(dir_original)\n","\n","set_samples = ['train', 'validation', 'test']\n","print(\"set_samples: \", set_samples, \"\\n\")\n","\n","CLASS_NAMES = np.array([item.name for item in sorted(data_dir.glob('*'))])\t\t\t\t\t\t\t\t\t\t\t\t\n","print(\"class: \", CLASS_NAMES, \"\\n\")\n","\n","N_IMAGES = np.array([len(list(data_dir.glob(item.name+'/*.jpg'))) for item in sorted(data_dir.glob('*'))])\t\t\t# number of images for class\n","print(\"number of images for class: \", N_IMAGES, \"\\n\")\n","\n","N_samples = np.array([(int(np.around(n*60/100)), int(np.around(n*15/100)), int(np.around(n*25/100))) for n in N_IMAGES])\t# number of images for set (train,validation,test)\n","print(\"split of dataset: \\n \", N_samples, \"\\n\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gmhOzI_Y9W8B"},"source":["**PREPROCESSING DATASET**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fsf53Pzk7xgT"},"outputs":[],"source":["# Create the new dataset\n","# Split Dataset\t\t\t\t\t\t\t\t(also resize and rotate)\n","\n","\n","\n","# create the dataset folder\t\t\t***********************************\n","os.makedirs(dir_processed)\n","\n","for set_tag in set_samples:\n","\tos.makedirs(dir_processed + '/' + set_tag)\n","\n","\tfor class_name in CLASS_NAMES:\n","\t\tos.makedirs(dir_processed + '/' + set_tag + '/' + class_name)\n","\n","\n","\n","# SPLIT DATASET (and resize)\t\t*************************************\n","print(\"Split dataset.....\")\n","\n","i=0\n","j=0\n","k=0\n","for class_name in CLASS_NAMES:\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \"j\" cambia con il tipo di pianta [0,3]\n","\t\n","    print(\"class name: \", class_name)\n","\n","    contatore_samples = 0\n","    k=0\n","\n","    array = sorted(os.listdir(dir_original + '/' + class_name))\n","    #random.shuffle(array)\n","\n","    for image_name in array:\t                                       \t# \"contatore\" si azzera ad ogni campo 'train' 'validation' 'test'\n","\t\n","        print(\"image: \", i)\n","        i=i+1\n","\n","        if contatore_samples==N_samples[j][k]:\t\t\t\t\t\t\t\t\t\t    # \"k\" cambia con train, validation, e test\n","            k+=1\n","            contatore_samples=0\n","\n","\n","        img=Image.open(dir_original +'/'+class_name+'/'+image_name)\n","        l,_ = img.size\n","        l=int(l)\n","        \n","        \n","        if l==1080 or l==720:\n","        \n","            transposed = img.transpose(Image.ROTATE_90)\n","            transposed.thumbnail(size)\n","            transposed.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n","        \n","        else:\n","        \n","            img.thumbnail(size)\n","            img.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n","\n","        contatore_samples+=1\t\n","\n","    j+=1\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"b5ecfMI2lffI"},"source":["# **MODEL for ESCA DATASET**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BhxyVMvTlipG"},"source":["LIBRARY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_X5lBUEJmN0k"},"outputs":[],"source":["import tensorflow as tf\n"," \n","from tensorflow import keras\n"," \n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n"," \n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n"," \n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time"]},{"cell_type":"markdown","metadata":{"id":"ituslInJllsc"},"source":["DIRECTORY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFNFmre4mOig"},"outputs":[],"source":["# cartelle contenenti il dataset\n"," \n","PATH_DATASET = '/content/drive/MyDrive/augmented_esca_dataset_splited'\n"," \n","train_data_dir = os.path.join(PATH_DATASET, 'train')\n","validation_data_dir = os.path.join(PATH_DATASET, 'validation')\n","test_data_dir = os.path.join(PATH_DATASET, 'test')\n"," \n"," \n"," \n","# nomi dei file da creare\n"," \n","PATH_MODELS = '/content/drive/MyDrive/Colab Notebooks/PAPER_1'\n"," \n","name_model_small = os.path.join(PATH_MODELS, 'model_small_b32.h5')\n","name_model_medium = os.path.join(PATH_MODELS, 'model_medium_b32.h5')\n","name_model_large = os.path.join(PATH_MODELS, 'model_large_b32.h5')"]},{"cell_type":"markdown","metadata":{"id":"i0RNUATslnli"},"source":["PARAMETERS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_BhD4g_MmPMr"},"outputs":[],"source":["batch_size = 32\n"," \n","nb_train_samples = 14868\n","nb_validation_samples = 3717\n","nb_test_samples = 6195\n"," \n","n_class = 2\n"," \n","epochs = 50"]},{"cell_type":"markdown","metadata":{"id":"0WQ9_a0bYAwq"},"source":["# **MODEL LARGE**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Rlacu5qYBhn"},"outputs":[],"source":["start = time.time()\n","\n","# image size (Model Medium)\n","img_width, img_height = 1280, 720\n","\n","# input shape\n","if keras.backend.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n","\n","\n","\n","# ***********************************************************************\n","# ************        DATASET       *************************************\n","# ***********************************************************************\n","\n","train_dataset = image_dataset_from_directory(train_data_dir,\n","                                             shuffle=True,\n","                                             batch_size=batch_size,\n","                                             image_size=(img_width, img_height),\n","                                             label_mode='categorical')\n","\n","\n","validation_dataset = image_dataset_from_directory(validation_data_dir,\n","                                                  shuffle=True,\n","                                                  batch_size=batch_size,\n","                                                  image_size=(img_width, img_height),\n","                                                  label_mode='categorical')\n","\n","\n","test_dataset = image_dataset_from_directory(test_data_dir,\n","                                            shuffle=True,\n","                                            batch_size=batch_size,\n","                                            image_size=(img_width, img_height),\n","                                            label_mode='categorical')\n","\n","\n","# preprocessing: input scaling (./255)\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\n","\n","\n","# Configure the dataset for performance\n","\n","#AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","#train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","#validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n","#test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","\n","\n","\n","# ***********************************************************************\n","# **************        MODEL       *************************************\n","# ***********************************************************************\n","\n","model_large = Sequential()\n","model_large.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(32, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(64, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(64, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(32, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Flatten())\n","model_large.add(Dense(64))\n","model_large.add(Activation('relu'))\n","model_large.add(Dropout(0.5))\n","model_large.add(Dense(2))\t\t\t#because we have 2 class\n","model_large.add(Activation('softmax'))\n","\n","model_large.summary()\n","\n","\n","# ***********************************************************************\n","# *******************        COMPILATION       **************************\n","# ***********************************************************************\n","\n","\n","model_large.compile(loss='categorical_crossentropy',\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\n","            metrics=['accuracy'])\n","\n","\n","\n","# ***********************************************************************\n","# *******************        TRAINING       *****************************\n","# ***********************************************************************\n","\n","\n","with tf.device('/device:GPU:0'):\n","\n","  history = model_large.fit(\n","    train_dataset,\n","    epochs=epochs,\n","    validation_data=validation_dataset)\n","\n","\n","\n","# ***********************************************************************\n","# *****************        SAVE MODEL        ****************************\n","# ***********************************************************************\n","\n","\n","model_large.save(name_model_large)\n","\n","\n","\n","# ***********************************************************************\n","# ********************        PLOT RESULTS        ***********************\n","# ***********************************************************************\n","\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\n","plt.show()\n","\n","\n","\n","# ***********************************************************************\n","# ***********************        TEST        ****************************\n","# ***********************************************************************\n","\n","with tf.device('/device:GPU:0'):\n","\n","  test_result = model_large.evaluate(test_dataset)\n","\n","  \n","print(\"size of images: \", img_width,img_height)\n","print(\"test_result: \", test_result)\n","\n","\n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"]},{"cell_type":"markdown","metadata":{"id":"UsAyqNAKaFjJ"},"source":["# **MODEL SMALL**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSAhC_EFaHdD"},"outputs":[],"source":["start = time.time()\n"," \n","# image size (Model Small)\n","img_width, img_height = 80, 45\n"," \n","# input shape\n","if keras.backend.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n"," \n"," \n"," \n","# ***********************************************************************\n","# ************        DATASET       *************************************\n","# ***********************************************************************\n"," \n","train_dataset = image_dataset_from_directory(train_data_dir,\n","                                             shuffle=True,\n","                                             batch_size=batch_size,\n","                                             image_size=(img_width, img_height),\n","                                             label_mode='categorical')\n"," \n"," \n","validation_dataset = image_dataset_from_directory(validation_data_dir,\n","                                                  shuffle=True,\n","                                                  batch_size=batch_size,\n","                                                  image_size=(img_width, img_height),\n","                                                  label_mode='categorical')\n"," \n"," \n","test_dataset = image_dataset_from_directory(test_data_dir,\n","                                            shuffle=True,\n","                                            batch_size=batch_size,\n","                                            image_size=(img_width, img_height),\n","                                            label_mode='categorical')\n"," \n"," \n","# preprocessing: input scaling (./255)\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\n"," \n"," \n","# Configure the dataset for performance\n"," \n","#AUTOTUNE = tf.data.experimental.AUTOTUNE\n"," \n","#train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","#validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n","#test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n"," \n"," \n"," \n"," \n","# ***********************************************************************\n","# **************        MODEL       *************************************\n","# ***********************************************************************\n"," \n","model_small = Sequential()\n","model_small.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(32, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(64, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(64, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(32, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Flatten())\n","model_small.add(Dense(64))\n","model_small.add(Activation('relu'))\n","model_small.add(Dropout(0.5))\n","model_small.add(Dense(2))           #because we have 2 class\n","model_small.add(Activation('softmax'))\n"," \n","model_small.summary()\n"," \n"," \n","# ***********************************************************************\n","# *******************        COMPILATION       **************************\n","# ***********************************************************************\n"," \n"," \n","model_small.compile(loss='categorical_crossentropy',\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\n","            metrics=['accuracy'])\n"," \n"," \n"," \n","# ***********************************************************************\n","# *******************        TRAINING       *****************************\n","# ***********************************************************************\n"," \n"," \n","with tf.device('/device:GPU:0'):\n"," \n","  history = model_small.fit(\n","    train_dataset,\n","    epochs=epochs,\n","    validation_data=validation_dataset)\n"," \n"," \n"," \n","# ***********************************************************************\n","# *****************        SAVE MODEL        ****************************\n","# ***********************************************************************\n"," \n"," \n","model_small.save(name_model_small)\n"," \n"," \n"," \n","# ***********************************************************************\n","# ********************        PLOT RESULTS        ***********************\n","# ***********************************************************************\n"," \n"," \n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n"," \n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n"," \n","epochs_range = range(epochs)\n"," \n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\n"," \n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\n","plt.show()\n"," \n"," \n"," \n","# ***********************************************************************\n","# ***********************        TEST        ****************************\n","# ***********************************************************************\n"," \n","with tf.device('/device:GPU:0'):\n"," \n","  test_result = model_small.evaluate(test_dataset)\n"," \n","  \n","print(\"size of images: \", img_width,img_height)\n","print(\"test_result: \", test_result)\n"," \n"," \n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"]},{"cell_type":"markdown","metadata":{"id":"qK6gqFKXWtUv"},"source":["# **MODEL MEDIUM**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xArrgnbWt3y"},"outputs":[],"source":["start = time.time()\n","\n","# image size (Model Medium)\n","img_width, img_height = 320, 180\n","\n","# input shape\n","if keras.backend.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n","\n","\n","\n","# ***********************************************************************\n","# ************        DATASET       *************************************\n","# ***********************************************************************\n","\n","train_dataset = image_dataset_from_directory(train_data_dir,\n","                                             shuffle=True,\n","                                             batch_size=batch_size,\n","                                             image_size=(img_width, img_height),\n","                                             label_mode='categorical')\n","\n","\n","validation_dataset = image_dataset_from_directory(validation_data_dir,\n","                                                  shuffle=True,\n","                                                  batch_size=batch_size,\n","                                                  image_size=(img_width, img_height),\n","                                                  label_mode='categorical')\n","\n","\n","test_dataset = image_dataset_from_directory(test_data_dir,\n","                                            shuffle=True,\n","                                            batch_size=batch_size,\n","                                            image_size=(img_width, img_height),\n","                                            label_mode='categorical')\n","\n","\n","# preprocessing: input scaling (./255)\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\n","\n","\n","# Configure the dataset for performance\n","\n","#AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","#train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","#validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n","#test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n","\n","\n","\n","\n","# ***********************************************************************\n","# **************        MODEL       *************************************\n","# ***********************************************************************\n","\n","model_medium = Sequential()\n","model_medium.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","model_medium.add(Activation('relu'))\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_medium.add(Conv2D(32, (3, 3), padding='same'))\n","model_medium.add(Activation('relu'))\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_medium.add(Conv2D(64, (3, 3), padding='same'))\n","model_medium.add(Activation('relu'))\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_medium.add(Conv2D(64, (3, 3), padding='same'))\n","model_medium.add(Activation('relu'))\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_medium.add(Conv2D(32, (3, 3), padding='same'))\n","model_medium.add(Activation('relu'))\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_medium.add(Flatten())\n","model_medium.add(Dense(64))\n","model_medium.add(Activation('relu'))\n","model_medium.add(Dropout(0.5))\n","model_medium.add(Dense(2))\t\t\t#because we have 2 class\n","model_medium.add(Activation('softmax'))\n","\n","model_medium.summary()\n","\n","\n","# ***********************************************************************\n","# *******************        COMPILATION       **************************\n","# ***********************************************************************\n","\n","\n","model_medium.compile(loss='categorical_crossentropy',\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\n","            metrics=['accuracy'])\n","\n","\n","\n","# ***********************************************************************\n","# *******************        TRAINING       *****************************\n","# ***********************************************************************\n","\n","\n","with tf.device('/device:GPU:0'):\n","\n","  history = model_medium.fit(\n","    train_dataset,\n","    epochs=epochs,\n","    validation_data=validation_dataset)\n","\n","\n","\n","# ***********************************************************************\n","# *****************        SAVE MODEL        ****************************\n","# ***********************************************************************\n","\n","\n","model_medium.save(name_model_medium)\n","\n","\n","\n","# ***********************************************************************\n","# ********************        PLOT RESULTS        ***********************\n","# ***********************************************************************\n","\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\n","plt.show()\n","\n","\n","\n","# ***********************************************************************\n","# ***********************        TEST        ****************************\n","# ***********************************************************************\n","\n","with tf.device('/device:GPU:0'):\n","\n","  test_result = model_medium.evaluate(test_dataset)\n","\n","  \n","print(\"size of images: \", img_width,img_height)\n","print(\"test_result: \", test_result)\n","\n","\n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMkX9UCnZv/2FgnP9IRdkpZ","collapsed_sections":[],"name":"esca_dataset-CNN.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.9.13 ('EmbIA')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"626023fc1712abc8bda09e65f0b98d23bcf071716da7f5a2faaca1749d8c250b"}}},"nbformat":4,"nbformat_minor":0}
